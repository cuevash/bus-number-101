{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: Reproducible Environments\n",
    "(Continued from `README.md`)\n",
    "\n",
    "## Overview\n",
    "\n",
    "* Requirements: The Bare Minimum \n",
    "\n",
    "* Using a Data Science Template: `cookiecutter`\n",
    "\n",
    "* Virtual Environments: `conda` and environment files\n",
    "* Revision Control: git and a git workflow\n",
    "   * Installing, Enabling, and using nbdime\n",
    "* The Data Science DAG\n",
    "   * make, Makefiles and data flow\n",
    "* Python Modules\n",
    "   * Creating an editable module\n",
    "* Testing: doctest, pytest, hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start out by checking that all the requirements are met from the previous exercises (started in `README.md`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Install the requirements\n",
    "\n",
    "* Anaconda\n",
    "* Cookiecutter\n",
    "* make\n",
    "* git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conda 4.13.0\r\n"
     ]
    }
   ],
   "source": [
    "!conda --version   # or `$CONDA_EXE --version` in some environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNU Make 3.81\r\n",
      "Copyright (C) 2006  Free Software Foundation, Inc.\r\n",
      "This is free software; see the source for copying conditions.\r\n",
      "There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A\r\n",
      "PARTICULAR PURPOSE.\r\n",
      "\r\n",
      "This program built for i386-apple-darwin11.3.0\r\n"
     ]
    }
   ],
   "source": [
    "!make --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "git version 2.35.1\r\n"
     ]
    }
   ],
   "source": [
    "!git --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Start your cookiecutter-based project\n",
    "\n",
    "Create a project called `Bus Number Tutorial`:\n",
    "\n",
    "    Use conda as your virtualenv manager\n",
    "    Use python 3.6 or greater\n",
    "\n",
    "When complete, you should have a fully populated project directory, complete with customized README.md.\n",
    "\n",
    "We will be working in this project from now on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2b:\n",
    "\n",
    "Explore the `README.md` from your new `bus_number_tutorial` repo\n",
    "\n",
    "(Hint: You can use the `%load` magic, or `!cat` to look at it in your notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bus-number-101\r\n",
      "==============================\r\n",
      "\r\n",
      "bus 101\r\n",
      "\r\n",
      "GETTING STARTED\r\n",
      "---------------\r\n",
      "\r\n",
      "* Create and switch to the  virtual environment:\r\n",
      "```\r\n",
      "cd bus-number-101\r\n",
      "make create_environment\r\n",
      "conda activate bus-number-101\r\n",
      "make requirements\r\n",
      "```\r\n",
      "* Explore the notebooks in the `notebooks` directory\r\n",
      "\r\n",
      "Project Organization\r\n",
      "------------\r\n",
      "* `LICENSE`\r\n",
      "* `Makefile`\r\n",
      "    * top-level makefile. Type `make` for a list of valid commands\r\n",
      "* `README.md`\r\n",
      "    * this file\r\n",
      "* `data`\r\n",
      "    * Data directory. often symlinked to a filesystem with lots of space\r\n",
      "    * `data/raw`\r\n",
      "        * Raw (immutable) hash-verified downloads\r\n",
      "    * `data/interim`\r\n",
      "        * Extracted and interim data representations\r\n",
      "    * `data/processed`\r\n",
      "        * The final, canonical data sets for modeling.\r\n",
      "* `docs`\r\n",
      "    * A default Sphinx project; see sphinx-doc.org for details\r\n",
      "* `models`\r\n",
      "    * Trained and serialized models, model predictions, or model summaries\r\n",
      "    * `models/trained`\r\n",
      "        * Trained models\r\n",
      "    * `models/output`\r\n",
      "        * predictions and transformations from the trained models\r\n",
      "* `notebooks`\r\n",
      "    *  Jupyter notebooks. Naming convention is a number (for ordering),\r\n",
      "    the creator's initials, and a short `-` delimited description,\r\n",
      "    e.g. `1.0-jqp-initial-data-exploration`.\r\n",
      "* `references`\r\n",
      "    * Data dictionaries, manuals, and all other explanatory materials.\r\n",
      "* `reports`\r\n",
      "    * Generated analysis as HTML, PDF, LaTeX, etc.\r\n",
      "    * `reports/figures`\r\n",
      "        * Generated graphics and figures to be used in reporting\r\n",
      "    * `reports/tables`\r\n",
      "        * Generated data tables to be used in reporting\r\n",
      "    * `reports/summary`\r\n",
      "        * Generated summary information to be used in reporting\r\n",
      "* `requirements.txt`\r\n",
      "    * (if using pip+virtualenv) The requirements file for reproducing the\r\n",
      "    analysis environment, e.g. generated with `pip freeze > requirements.txt`\r\n",
      "* `environment.yml`\r\n",
      "    * (if using conda) The YAML file for reproducing the analysis environment\r\n",
      "* `setup.py`\r\n",
      "    * Turns contents of `src` into a\r\n",
      "    pip-installable python module  (`pip install -e .`) so it can be\r\n",
      "    imported in python code\r\n",
      "* `src`\r\n",
      "    * Source code for use in this project.\r\n",
      "    * `src/__init__.py`\r\n",
      "        * Makes src a Python module\r\n",
      "    * `src/data`\r\n",
      "        * Scripts to fetch or generate data. In particular:\r\n",
      "        * `src/data/make_dataset.py`\r\n",
      "            * Run with `python -m src.data.make_dataset fetch`\r\n",
      "            or  `python -m src.data.make_dataset process`\r\n",
      "    * `src/analysis`\r\n",
      "        * Scripts to turn datasets into output products\r\n",
      "    * `src/models`\r\n",
      "        * Scripts to train models and then use trained models to make predictions.\r\n",
      "        e.g. `predict_model.py`, `train_model.py`\r\n",
      "* `tox.ini`\r\n",
      "    * tox file with settings for running tox; see tox.testrun.org\r\n",
      "\r\n",
      "\r\n",
      "--------\r\n",
      "\r\n",
      "<p><small>This project was built using <a target=\"_blank\" href=\"https://github.com/hackalog/cookiecutter-easydata\">cookiecutter-easydata</a>, an experimental fork of [cookiecutter-data-science](https://github.com/drivendata/cookiecutter-data-science) aimed at making your data science workflow reproducible.</small></p>\r\n"
     ]
    }
   ],
   "source": [
    "!cat ../README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Set up your virtual environment and install all dependencies\n",
    "\n",
    "Create and activate your `bus_number_tutorial` conda environment using the above make commands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your `active environment` should be `bus_number_tutorial`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "     active environment : bus-number-101\r\n",
      "    active env location : /Users/hector/opt/anaconda3/envs/bus-number-101\r\n",
      "            shell level : 2\r\n",
      "       user config file : /Users/hector/.condarc\r\n",
      " populated config files : \r\n",
      "          conda version : 4.13.0\r\n",
      "    conda-build version : 3.18.11\r\n",
      "         python version : 3.7.6.final.0\r\n",
      "       virtual packages : __osx=10.16=0\r\n",
      "                          __unix=0=0\r\n",
      "                          __archspec=1=x86_64\r\n",
      "       base environment : /Users/hector/opt/anaconda3  (writable)\r\n",
      "      conda av data dir : /Users/hector/opt/anaconda3/etc/conda\r\n",
      "  conda av metadata url : None\r\n",
      "           channel URLs : https://repo.anaconda.com/pkgs/main/osx-64\r\n",
      "                          https://repo.anaconda.com/pkgs/main/noarch\r\n",
      "                          https://repo.anaconda.com/pkgs/r/osx-64\r\n",
      "                          https://repo.anaconda.com/pkgs/r/noarch\r\n",
      "          package cache : /Users/hector/opt/anaconda3/pkgs\r\n",
      "                          /Users/hector/.conda/pkgs\r\n",
      "       envs directories : /Users/hector/opt/anaconda3/envs\r\n",
      "                          /Users/hector/.conda/envs\r\n",
      "               platform : osx-64\r\n",
      "             user-agent : conda/4.13.0 requests/2.22.0 CPython/3.7.6 Darwin/21.4.0 OSX/10.16\r\n",
      "                UID:GID : 501:20\r\n",
      "             netrc file : None\r\n",
      "           offline mode : False\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!conda info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If you are using **JupyterHub**, the bash magics `!` and `%%bash` will not work as expected, that is, they will drop you into your root JupyterHub environment, as opposed to the conda kernel that you a running this notebook in, and you will not see `bus_number_tutorial`. To get around this, you will need to run the bash commands in this notebook from a terminal instance with your `bus_number_tutorial` conda environment activated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If done correctly, you should also be able to import from `src`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if importing src doesn't work, try `make requirements`\n",
    "import src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Pick up this tutorial in your new repo\n",
    "\n",
    "* Run jupyter notebook and open `notebooks/10-reproducible-environment.ipynb`\n",
    "\n",
    "If you're currently running this notebook and the checks from the previous exercises worked, then you're in business!\n",
    "\n",
    "Keep going from here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revision Control: `git`\n",
    "\n",
    "How do we keep track of our changes? We use **git**.\n",
    "\n",
    "Before we do anything interesting, let's initialize a git repository (repo) here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Initialize a git repo for `bus_number_tutorial`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "git init\n",
    "git add .\n",
    "git commit -m \"Initial Import\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\r\n",
      "nothing to commit, working tree clean\r\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will get back to using git again soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6: Add a dependency\n",
    "Modify the environment file so that `make requirements` installs some additional packages\n",
    "* install `joblib` using conda\n",
    "* install `nbdime` using pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that you now have joblib  and nbdime installed\n",
    "# Don't forget that you need to run `make requirements` once you've change the `environment.yml` file\n",
    "import joblib\n",
    "import nbdime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7: Basic git interactions\n",
    "\n",
    "Check the changes to your `environment.yml` file into your git repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See what has changed with git:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\r\n",
      "Changes not staged for commit:\r\n",
      "  (use \"git add <file>...\" to update what will be committed)\r\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\r\n",
      "\t\u001b[31mmodified:   ../environment.lock\u001b[m\r\n",
      "\t\u001b[31mmodified:   ../environment.yml\u001b[m\r\n",
      "\t\u001b[31mmodified:   10-reproducible-environment.ipynb\u001b[m\r\n",
      "\r\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\r\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mdiff --git a/environment.yml b/environment.yml\u001b[m\r\n",
      "\u001b[1mindex 5e8c244..d9d7e11 100644\u001b[m\r\n",
      "\u001b[1m--- a/environment.yml\u001b[m\r\n",
      "\u001b[1m+++ b/environment.yml\u001b[m\r\n",
      "\u001b[36m@@ -2,9 +2,10 @@\u001b[m \u001b[mname: bus-number-101\u001b[m\r\n",
      " dependencies:\u001b[m\r\n",
      "   - pip\u001b[m\r\n",
      "   - pip:\u001b[m\r\n",
      "\u001b[31m-    - -e .  # conda >= 4.4 only\u001b[m\r\n",
      "\u001b[31m-    - python-dotenv>=0.5.1\u001b[m\r\n",
      "\u001b[31m-    - nbval\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m      - -e . # conda >= 4.4 only\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m      - python-dotenv>=0.5.1\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m      - nbval\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m      - nbdime\u001b[m\r\n",
      "   - setuptools\u001b[m\r\n",
      "   - wheel\u001b[m\r\n",
      "   - sphinx\u001b[m\r\n",
      "\u001b[36m@@ -15,5 +16,5 @@\u001b[m \u001b[mdependencies:\u001b[m\r\n",
      "   - nb_conda\u001b[m\r\n",
      "   - pandas\u001b[m\r\n",
      "   - requests\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m  - joblib\u001b[m\r\n",
      "   - python>=3.6\u001b[m\r\n",
      "\u001b[31m-\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!git diff -u ../environment.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add or reject your changes incrementally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git add -p\n",
    "#!git reset -p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commit the changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hint: Waiting for your editor to close the file... \u001b7\u001b[?47h\u001b[>4;2m\u001b[?1h\u001b=\u001b[?2004h\u001b[?1004h\u001b[1;24r\u001b[?12h\u001b[?12l\u001b[22;2t\u001b[22;1t\u001b[29m\u001b[m\u001b[H\u001b[2J\u001b[?25l\u001b[24;1H\"~/code_projects/eternal-rtn/bus-number-101/.git/COMMIT_EDITMSG\" 91L, 2378B\u001b[2;1Hâ–½\u001b[6n\u001b[2;1H  \u001b[3;1H\u001bPzz\u001b\\\u001b[0%m\u001b[6n\u001b[3;1H           \u001b[1;1H\u001b[>c\u001b]10;?\u0007\u001b]11;?\u0007\u001b[2;1H# Please enter the commit message for your changes. Lines starting\u001b[2;67H\u001b[K\u001b[3;1H# with '#' will be ignored, and an empty message aborts the commit.\u001b[3;68H\u001b[K\u001b[4;1H#\n",
      "# On branch main\n",
      "# Changes to be committed:\n",
      "#\u001b[7Cmodified:   ../environment.lock\n",
      "#\u001b[7Cmodified:   ../environment.yml\n",
      "#\u001b[7Cmodified:   10-reproducible-environment.ipynb\n",
      "#\n",
      "# ------------------------ >8 ------------------------\n",
      "# Do not modify or remove the line above.\n",
      "# Everything below it will be ignored.\n",
      "diff --git a/environment.lock b/environment.lock\n",
      "index 9547873..53606c9 100644\n",
      "--- a/environment.lock\n",
      "+++ b/environment.lock\n",
      "@@ -41,6 +41,7 @@ dependencies:\n",
      "   - ipywidgets=7.6.5=pyhd3eb1b0_1\n",
      "   - jedi=0.18.1=py39hecd8cb5_1\n",
      "   - jinja2=3.0.3=pyhd3eb1b0_0\n",
      "+  - joblib=1.1.0=pyhd3eb1b0_0\n",
      "   - jpeg=9e=hca72f7f_0\u001b[1;1H\u001b[?25h\u001b[?25l\u001b[24;1HType  :qa  and press <Enter> to exit Vim\u001b[24;41H\u001b[K\u0007\u001b[1;1H\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!git commit -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\r\n",
      "Changes not staged for commit:\r\n",
      "  (use \"git add <file>...\" to update what will be committed)\r\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\r\n",
      "\t\u001b[31mmodified:   10-reproducible-environment.ipynb\u001b[m\r\n",
      "\r\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\r\n"
     ]
    }
   ],
   "source": [
    "# You should have no differences in your branch now\n",
    "# Except for those that you've made by running notebooks\n",
    "!git status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data Science DAG\n",
    "DAG = Directed Acyclic Graph. \n",
    "\n",
    "That means the process eventually stops. (This is a good thing!) \n",
    "\n",
    "It also means we can use a super old, but incredibly handy tool to implement this workflow: `make`.\n",
    "\n",
    "### Make, Makefiles, and the Data Flow\n",
    "\n",
    "\n",
    "We use a `Makefile` to organize and invoke the various steps in our Data Science pipeline.\n",
    "You have already used this file when you created your virtual environment in the first place:\n",
    "```\n",
    "make create_environment\n",
    "```\n",
    "Here are the steps we will be working through in this tutorial:\n",
    "<img src=\"references/cheat_sheet.png\" alt=\"Reproducible Data Science Workflow\" width=\"400\"/>\n",
    "\n",
    "A [PDF version of the cheat sheet](references/cheat_sheet.pdf) is also available.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### What's my make target doing?\n",
    "If you are ever curious what commands a `make` command will invoke (including any invoked dependencies), use `make -n`, which lists the commands without executing them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 test_environment.py\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd .. && make -n requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a cute **self-documenting makefiles trick** (borrowed from `cookiecutter-datascience`) to make it easy to document the various targets that you add. This documentation is produced when you type a plain `make`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To get started:\n",
      "  >>> \u001b[1mmake create_environment\u001b[m\n",
      "  >>> \u001b[1mconda activate bus-number-101\u001b[m\n",
      "\n",
      "\u001b[1mProject Variables:\u001b[m\n",
      "PROJECT_NAME = bus-number-101\n",
      "\n",
      "\u001b[1mAvailable rules:\u001b[m\n",
      "\u001b[36manalysis           \u001b[m Convert predictions / transforms / experiments into output \n",
      "                    data \n",
      "\u001b[36mclean              \u001b[m Delete all compiled Python files \n",
      "\u001b[36mclean_interim      \u001b[m Delete all interim (DataSource) files \n",
      "\u001b[36mclean_models       \u001b[m Delete all trained models \n",
      "\u001b[36mclean_predictions  \u001b[m Delete all predictions \n",
      "\u001b[36mclean_processed    \u001b[m Delete all processed datasets \n",
      "\u001b[36mclean_raw          \u001b[m Delete the raw downloads directory \n",
      "\u001b[36mcreate_environment \u001b[m Set up virtual environment for this project \n",
      "\u001b[36mdata               \u001b[m convert raw datasets into fully processed datasets \n",
      "\u001b[36mdelete_environment \u001b[m Delete the virtual environment for this project \n",
      "\u001b[36mlint               \u001b[m Lint using flake8 \n",
      "\u001b[36mpredict            \u001b[m predict / transform / run experiments \n",
      "\u001b[36mrequirements       \u001b[m Install or update Python Dependencies \n",
      "\u001b[36msources            \u001b[m Fetch, Unpack, and Process raw DataSources \n",
      "\u001b[36msync_data_from_s3  \u001b[m Download Data from S3 \n",
      "\u001b[36msync_data_to_s3    \u001b[m Upload Data to S3 \n",
      "\u001b[36mtest               \u001b[m Run all Unit Tests \n",
      "\u001b[36mtest_environment   \u001b[m Test python environment is set-up correctly \n",
      "\u001b[36mtrain              \u001b[m train / fit / build models \n",
      "\u001b[36mtransform_data     \u001b[m Apply Transformations to produce fully processed Datsets \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd .. && make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Under the Hood: The Format of a Makefile\n",
    "\n",
    "```\n",
    "## Comment to appear in the auto-generated documentation\n",
    "thing_to_build: space separated list of dependencies\n",
    "\tcommand_to_run            # there is a tab before this command.\n",
    "\tanother_command_to_run    # every line gets run in a *new shell*\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Makefile.test\n"
     ]
    }
   ],
   "source": [
    "%%file Makefile.test\n",
    "\n",
    "data: raw\n",
    "\t@echo \"Build Datasets\"\n",
    "train_test_split:\n",
    "\t@echo \"do train/test split\"\n",
    "train: data transform_data train_test_split\n",
    "\t@echo \"Train Models\"\n",
    "transform_data:\n",
    "\t@echo \"do a data transformation\"\n",
    "raw:\n",
    "\t@echo \"Fetch raw data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetch raw data\r\n",
      "Build Datasets\r\n"
     ]
    }
   ],
   "source": [
    "# Note: you can run a specific Makefile with with -f option\n",
    "!make -f Makefile.test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If you see: ```*** missing separator.  Stop.``` it's because you have used spaces instead of **tabs** before your commands. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8: What does this `Makefile.test` print when you run `make train`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetch raw data\r\n",
      "Build Datasets\r\n",
      "do a data transformation\r\n",
      "do train/test split\r\n",
      "Train Models\r\n"
     ]
    }
   ],
   "source": [
    "!make -f Makefile.test train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9: What happens when you add a cycle to a Makefile\n",
    "Set up a makefile with a cyclic dependency and run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Makefile.test\n"
     ]
    }
   ],
   "source": [
    "%%file Makefile.test\n",
    "\n",
    "data: raw\n",
    "\t@echo \"Build Datasets\"\n",
    "train_test_split:\n",
    "\t@echo \"do train/test split\"\n",
    "train: data transform_data train_test_split\n",
    "\t@echo \"Train Models\"\n",
    "transform_data:\n",
    "\t@echo \"do a data transformation\"\n",
    "raw: data\n",
    "\t@echo \"Fetch raw data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: Circular raw <- data dependency dropped.\r\n",
      "Fetch raw data\r\n",
      "Build Datasets\r\n"
     ]
    }
   ],
   "source": [
    "!make -f Makefile.test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a Makefile like this is an easy way to set up a process flow expressed as a Directed Acyclic Graph (DAG).\n",
    "\n",
    "**Note**: We have only scratched the surface here. The are lots of interesting tricks you can do with make.\n",
    "* http://zmjones.com/make/\n",
    "* http://blog.byronjsmith.com/makefile-shortcuts.html\n",
    "* https://www.gnu.org/software/make/manual/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to Revision Control: git workflows\n",
    "\n",
    "Git isn't really a collaboration tool. It's more a tool for implementing collaboration workflows.\n",
    "\n",
    "What do we mean by workflow? A process built on top of git that incorporates **pull requests** and **branches**. Typically, this is provided by sites like: GitHub, GitLab, BitBucket.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10: \n",
    "\n",
    "Create a GitHub/GitLab/BitBucket repo and sync your repo to it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin\tgit@github.com:cuevash/bus-number-101.git (fetch)\r\n",
      "origin\tgit@github.com:cuevash/bus-number-101.git (push)\r\n"
     ]
    }
   ],
   "source": [
    "# your remote repo should now show up\n",
    "!git remote -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example (using SSL):\n",
    "\n",
    "    origin\tgit@github.com:${GITHUB_USERNAME}/bus_number_tutorial.git (fetch)\n",
    "   \n",
    "    origin\tgit@github.com:${GITHUB_USERNAME}/bus_number_tutorial.git (push)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GitHub workflow cheatsheet\n",
    "See https://github.com/hackalog/bus_number/wiki/Github-Workflow-Cheat-Sheet\n",
    "\n",
    "## Life Rules for using `git`\n",
    "\n",
    "* Always work on a branch: `git checkout -b my_branch_name`. Delete branches once they are merged.\n",
    "* **Never** push to master. Always **work on a branch** and do a pull request.\n",
    "* Seriously, don't do work on master if you are collaborating with **anyone**.\n",
    "* If you pushed it anywhere, or shared it with anyone, don't `git rebase`. In fact, if you're reading this, don't `git rebase`. Save that for when you are comfortable solving git merge nightmares on your own.\n",
    "\n",
    "Here are some common tasks in git/github\n",
    "\n",
    "### Starting the day. Where was I? What was I doing?\n",
    "```\n",
    "git branch         # What branch am I currently on? e.g. {my_branch}\n",
    "git status         # anything I forgot to commit? If so...\n",
    "git commit ...     # Commit work in progress\n",
    "```\n",
    "\n",
    "### Didn't I do some work at home last night?\n",
    "```\n",
    "git checkout master       # leave whatever branch I was on\n",
    "git fetch origin --prune  # Check for something new\n",
    "git merge origin/master   # If updates available, update!\n",
    "git branch --merged master # check for any merged branches that can be safely deleted\n",
    "git branch -d {name_of_merged_branch} # delete any fully merged branches\n",
    "```\n",
    "\n",
    "### Anything fun happening upstream?\n",
    "\n",
    "```\n",
    "git checkout master\n",
    "git fetch upstream --prune  # grab latest changes from upstream repo\n",
    "git merge upstream/master   # merge them into local copy of my form\n",
    "git push origin master      # push latest upstream changes to my forked repo\n",
    "git branch --merged master # check for any merged branches that can be safely deleted\n",
    "git branch -d {name_of_merged_branch} # delete any fully merged branches\n",
    "```\n",
    "\n",
    "Now that `master` is up to date, you should merge whatever happened in `master` into your development branch:\n",
    "```\n",
    "git checkout {my_branch}\n",
    "git merge master               # merges master->{my_branch}\n",
    "git push origin {my_branch}    # Let Github know about the merge\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some useful references if `gitflow` isn't second nature to you yet\n",
    "* Introduction to GitHub tutorial: https://lab.github.com/githubtraining/introduction-to-github\n",
    "* Git Handbook: https://guides.github.com/introduction/git-handbook/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11:\n",
    "* Create a branch called `add_sklearn`\n",
    "* Add a scikit-learn dependency\n",
    "* Check in these changes using git to your local repo\n",
    "* Push the new branch to GitHub\n",
    "* Create a pull request to merge this branch into master\n",
    "* Merge your PR (delete the branch afterwards)\n",
    "* Sync your local repo with GitHub, including deleting the merged branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Modules\n",
    "By default, we keep our source code in a module called `src`. (this can be overridden in the cookieccutter)\n",
    "\n",
    "This is enabled via one line in `environment.yml`:\n",
    "```\n",
    "- pip:\n",
    "  - -e .\n",
    "```\n",
    "\n",
    "This creates an **editable module**, and looks in the current directory for a file called `setup.py` to indicate the module name and location"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# %load ../setup.py\n",
    "from setuptools import find_packages, setup\n",
    "\n",
    "setup(\n",
    "    name='src',\n",
    "    packages=find_packages(),\n",
    "    version='0.0.1',\n",
    "    description='Up Your Bus Number: A Primer for Reproducible Data Science',\n",
    "    author='Tutte Institute for Mathematics and Computing',\n",
    "    license='MIT',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lets you easily use your code in notebooks and other scripts, and avoids any `sys.path.append` silliness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASIDE: Semantic Versioning\n",
    "\n",
    "Semantic versioning (or *semver*), refers to the convention of versioning with a triple:\n",
    "\n",
    "    MAJOR.MINOR.PATCH\n",
    "\n",
    "With the following convention: when releasing new versions, increment the:\n",
    "\n",
    "*    MAJOR version when you make **incompatible API changes**,\n",
    "*    MINOR version when you **add functionality** in a backwards-compatible manner, and\n",
    "*    PATCH version when you make backwards-compatible **bug fixes**.\n",
    "\n",
    "If you have no other plan, this is a great convention to follow.\n",
    "\n",
    "For an obscene amount of detail on this concept, see https://semver.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11:\n",
    "* add your favorite utility function to `src/utils`\n",
    "* increment the version number of the editable package (do this in `setup.py`)\n",
    "* run `make requirements` (required if you added dependencies for your utility function)\n",
    "* import your utility function and run it from this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A handy magic that allows us to edit modules and have them stay up to date in the notebook. In this case, src.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing: doctest, pytest, coverage\n",
    "\n",
    "\n",
    "Python has built in testing frameworks via:\n",
    "* doctests:https://docs.python.org/3/library/doctest.html#module-doctest\n",
    "* unittest: https://docs.python.org/3/library/unittest.html\n",
    "\n",
    "Additionally, you'll want to make regular use of:\n",
    "* pytest: https://docs.pytest.org/en/latest/\n",
    "* pytest-cov: https://pypi.org/project/pytest-cov/\n",
    "* hypothesis: https://hypothesis.readthedocs.io/en/latest\n",
    "\n",
    "Cookiecutter (vanilla flavoured) comes witha setup for the `tox` testing framework built in.\n",
    "* https://tox.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12:\n",
    "\n",
    "Add a `make test` target to your makefile that:\n",
    "* runs doctests\n",
    "* runs pytest unit tests\n",
    "* (extra credit) Displays test coverage results\n",
    "    \n",
    "When you run `make test`, you will find tests that will fail in `src/test_example.py`. Fix them in the next exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd .. && make test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note:*** `make test` is normally functionality built into `cookiecutter-easydata`. We're building it from scratch here for the sake of practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 13:\n",
    "Fix the failing tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should pass all tests now!\n",
    "!cd .. && make test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 14:\n",
    "* Check in all your changes to git\n",
    "* Merge them into your master branch via a PR in GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
